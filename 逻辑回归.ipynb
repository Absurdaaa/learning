{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归\n",
    "## 二分类算法\n",
    "* Sigmiod函数，1/(1+exp(theta * X)),用于把特征值变成范围为0-1，相当于一个概率值，当大于0.5时分为1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        47\n",
      "           1       0.97      0.94      0.95        67\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.95      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Accuracy: 94.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linshangjin/Desktop/python/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/linshangjin/Desktop/python/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 乳腺癌数据集，希望做个二分类模型去判别是否为癌症\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data=cancer[\"data\"]\n",
    "col = cancer['feature_names']       #提取特征的名字\n",
    "x = pd.DataFrame(data,columns=col)  #那些特征的数值,30个特征，569个数据\n",
    "target = cancer.target.astype(int)\n",
    "y = pd.DataFrame(target,columns=['target'])#对应特征组合下的类别标签\n",
    "\n",
    "# 划分数据集\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "model = LogisticRegression()#默认参数\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# 计算准确率  \n",
    "accuracy = np.mean(y_pred == y_test.T)  \n",
    "print(f'Accuracy: {accuracy * 100:.2f}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是用梯度下降优化器来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.96      0.76        47\n",
      "           1       0.95      0.61      0.75        67\n",
      "\n",
      "    accuracy                           0.75       114\n",
      "   macro avg       0.79      0.78      0.75       114\n",
      "weighted avg       0.82      0.75      0.75       114\n",
      "\n",
      "Accuracy: 75.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linshangjin/Desktop/python/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier  \n",
    "\n",
    "# 创建 SGDClassifier，使用逻辑回归  \n",
    "\n",
    "model = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3,random_state=0)  # 设置 loss='log' 用于逻辑回归  \n",
    "\n",
    "# 训练模型  \n",
    "model.fit(x_train, y_train)  \n",
    "\n",
    "# 进行预测  \n",
    "y_pred = model.predict(x_test)  \n",
    "\n",
    "# 输出分类报告  \n",
    "report = classification_report(y_test, y_pred)  \n",
    "print(report)\n",
    "# 计算准确率  \n",
    "accuracy = np.mean(y_pred == y_test.T)  \n",
    "print(f'Accuracy: {accuracy * 100:.2f}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来手动实现一下逻辑回归，还是用上面的数据来分类癌症患者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.35%\n"
     ]
    }
   ],
   "source": [
    "import warnings  \n",
    "# 忽略所有的 RuntimeWarning  \n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 癌症数据集，希望做个二分类模型去判别是否为癌症\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data=cancer[\"data\"]\n",
    "col = cancer['feature_names']       #提取特征的名字\n",
    "X = pd.DataFrame(data,columns=col)  #那些特征的数值,30个特征，569个数据\n",
    "target = cancer.target.astype(int)\n",
    "y = pd.DataFrame(target,columns=['target'])#对应特征组合下的类别标签\n",
    "y=y.to_numpy()\n",
    "\n",
    "X_b=np.concatenate([np.ones((len(y),1)),X],axis=1)\n",
    "\n",
    "# 划分数据集\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_b,y,test_size=0.2,random_state=0)\n",
    "\n",
    "# 学习率衰减策略，迭代到后面学习率逐渐变小\n",
    "t0,t1=5,50\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "# 迭代次数\n",
    "n_epoch=10000\n",
    "# 初始化待求参数\n",
    "theta=np.ones((31,1))\n",
    "# 使用样本数\n",
    "m=len(y_test)\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    Sigmoid=1/(1+np.exp(-theta.T.dot(x_train.T)))\n",
    "\n",
    "    gradients= -1/m * (y_train.T-Sigmoid).dot(x_train)\n",
    "    eta=learning_schedule(epoch)\n",
    "    theta=theta - eta*gradients.T\n",
    "\n",
    "# 验证集检验\n",
    "y_test_pred=(1/(1+np.exp(-theta.T.dot(x_test.T)))>0.5).astype(int)\n",
    "\n",
    "# 计算准确率  \n",
    "accuracy = np.mean(y_test_pred == y_test.T)  \n",
    "print(f'Accuracy: {accuracy * 100:.2f}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是去掉常数项之后的结果，比原本的结果略差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.84%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 癌症数据集，希望做个二分类模型去判别是否为癌症\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data=cancer[\"data\"]\n",
    "col = cancer['feature_names']       #提取特征的名字\n",
    "X = pd.DataFrame(data,columns=col)  #那些特征的数值,30个特征，569个数据\n",
    "target = cancer.target.astype(int)\n",
    "y = pd.DataFrame(target,columns=['target'])#对应特征组合下的类别标签\n",
    "\n",
    "# 划分数据集\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "# 学习率衰减策略，迭代到后面学习率逐渐变小\n",
    "t0,t1=5,50\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "# 迭代次数\n",
    "n_epoch=1000\n",
    "# 初始化待求参数\n",
    "theta=np.ones((30,1))\n",
    "# 使用样本数\n",
    "m=len(y_test)\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    Sigmoid=1/(1+np.exp(-theta.T.dot(x_train.T)))\n",
    "    gradients= -1/m * (y_train.T-Sigmoid).dot(x_train)\n",
    "    eta=learning_schedule(epoch)\n",
    "    theta=theta - eta*gradients.T\n",
    "\n",
    "# 验证集检验\n",
    "y_test_pred=(1/(1+np.exp(-theta.T.dot(x_test.T)))>0.5).astype(int)\n",
    "\n",
    "# 计算准确率  \n",
    "accuracy = np.mean(y_test_pred == y_test.T)  \n",
    "print(f'Accuracy: {accuracy * 100:.2f}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多类别分类   \n",
    "* 多分类用到solfmax，就是多个类别的概率归一化，然后求损失函数最小，\n",
    "    这里用到一个鸢尾花的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "# 可以打印数据集的说明\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.64127138e-01 3.58727086e-02 1.53820941e-07]]\n",
      "[4.6 3.4 1.4 0.3]\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data['data']\n",
    "y=data[\"target\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "log_res=LogisticRegression(solver='lbfgs')\n",
    "log_res.fit(X_train,y_train)\n",
    "y_pred=log_res.predict(X_test)\n",
    "# 这个函数可以返回每个类别的概率值\n",
    "print(log_res.predict_proba(X_test[1:2,:]))\n",
    "\n",
    "accuracy=np.mean((y_pred==y_test).astype(int))\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
